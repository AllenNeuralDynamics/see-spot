{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d204e4f",
   "metadata": {},
   "source": [
    "# SeeSpot API Query Example\n",
    "\n",
    "This notebook demonstrates how to query the `get_real_spots_data` API endpoint from your SeeSpot FastAPI application and process the response data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The API endpoint `/api/real_spots_data` returns:\n",
    "- **channel_pairs**: Available channel combinations for visualization\n",
    "- **spots_data**: Individual spot records with intensities and metadata\n",
    "- **spot_details**: Detailed coordinates and cell information for neuroglancer\n",
    "- **fused_s3_paths**: S3 paths to fused image data\n",
    "- **ratios** (optional): Spectral unmixing ratio matrix\n",
    "- **summary_stats** (optional): Processing summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ef8f8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for making API requests and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4381de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Set up plotting style\n",
    "# plt.style.use('default')\n",
    "# sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f30778",
   "metadata": {},
   "source": [
    "## 2. Set Up API Configuration\n",
    "\n",
    "Configure the API endpoint and request parameters. Make sure your SeeSpot server is running on the specified port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df0f698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Endpoint: http://localhost:9995/api/real_spots_data\n",
      "Parameters: {'sample_size': 5000, 'force_refresh': False}\n"
     ]
    }
   ],
   "source": [
    "# API Configuration\n",
    "BASE_URL = \"http://localhost:9995\"  # Adjust port if different\n",
    "API_ENDPOINT = f\"{BASE_URL}/api/real_spots_data\"\n",
    "\n",
    "# Request parameters\n",
    "params = {\n",
    "    \"sample_size\": 5000,        # Number of spots to sample\n",
    "    \"force_refresh\": False      # Set to True to bypass cache\n",
    "}\n",
    "\n",
    "print(f\"API Endpoint: {API_ENDPOINT}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69baff",
   "metadata": {},
   "source": [
    "## 3. Make the API Request\n",
    "\n",
    "Send a GET request to the API endpoint and handle the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adda11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API request...\n",
      "‚úÖ Success! Status code: 200\n",
      "üìä Response data type: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Make the API request\n",
    "    print(\"Making API request...\")\n",
    "    response = requests.get(API_ENDPOINT, params=params, timeout=60)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚úÖ Success! Status code: {response.status_code}\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        print(f\"üìä Response data type: {type(data)}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Error! Status code: {response.status_code}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "        data = None\n",
    "        \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Request failed: {e}\")\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff036d",
   "metadata": {},
   "source": [
    "## 4. Parse and Explore the Response\n",
    "\n",
    "Examine the structure of the returned data and understand what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05365da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Exploring API response structure...\n",
      "Response keys: ['channel_pairs', 'spots_data', 'spot_details', 'fused_s3_paths', 'ratios', 'summary_stats']\n",
      "\n",
      "üìã channel_pairs: list with 10 items\n",
      "   First item type: <class 'list'>\n",
      "\n",
      "üìã spots_data: list with 5000 items\n",
      "   First item type: <class 'dict'>\n",
      "   First item keys: ['spot_id', 'chan', 'r', 'dist', 'unmixed_chan']...\n",
      "\n",
      "üìö spot_details: dict with 5000 keys\n",
      "   Sample keys: ['7966486', '5243252', '7691947']...\n",
      "\n",
      "üìã fused_s3_paths: list with 5 items\n",
      "   First item type: <class 'str'>\n",
      "\n",
      "üìã ratios: list with 5 items\n",
      "   First item type: <class 'list'>\n",
      "\n",
      "üìã summary_stats: list with 5 items\n",
      "   First item type: <class 'dict'>\n",
      "   First item keys: ['min_dist', 'round', 'total_spots', 'kept_spots', 'reassigned_spots']...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if data is not None:\n",
    "    print(\"üîç Exploring API response structure...\")\n",
    "    print(f\"Response keys: {list(data.keys())}\")\n",
    "    print()\n",
    "    \n",
    "    # Examine each component\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"üìã {key}: list with {len(value)} items\")\n",
    "            if len(value) > 0:\n",
    "                print(f\"   First item type: {type(value[0])}\")\n",
    "                if isinstance(value[0], dict):\n",
    "                    print(f\"   First item keys: {list(value[0].keys())[:5]}...\")\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"üìö {key}: dict with {len(value)} keys\")\n",
    "            print(f\"   Sample keys: {list(value.keys())[:3]}...\")\n",
    "        else:\n",
    "            print(f\"üìÑ {key}: {type(value)} - {value}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available. Make sure the SeeSpot server is running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f210b3",
   "metadata": {},
   "source": [
    "## 5. Extract Specific Data Components\n",
    "\n",
    "Convert the API response into useful data structures for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1ef843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Current DataFrame Info:\n",
      "Shape: (5000, 12)\n",
      "Memory usage: 0.89 MB\n",
      "\n",
      "üìã Current Data Types:\n",
      "spot_id                 int64\n",
      "chan                   object\n",
      "r                     float64\n",
      "dist                  float64\n",
      "unmixed_chan           object\n",
      "reassigned               bool\n",
      "unmixed_removed          bool\n",
      "chan_488_intensity    float64\n",
      "chan_514_intensity    float64\n",
      "chan_561_intensity    float64\n",
      "chan_594_intensity    float64\n",
      "chan_638_intensity    float64\n",
      "dtype: object\n",
      "\n",
      "üíæ Memory Usage by Column:\n",
      "  Index: 0.1 KB\n",
      "  spot_id: 39.1 KB\n",
      "  chan: 293.0 KB\n",
      "  r: 39.1 KB\n",
      "  dist: 39.1 KB\n",
      "  unmixed_chan: 293.0 KB\n",
      "  reassigned: 4.9 KB\n",
      "  unmixed_removed: 4.9 KB\n",
      "  chan_488_intensity: 39.1 KB\n",
      "  chan_514_intensity: 39.1 KB\n",
      "  chan_561_intensity: 39.1 KB\n",
      "  chan_594_intensity: 39.1 KB\n",
      "  chan_638_intensity: 39.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Let's check the current memory usage and data types\n",
    "if data is not None:\n",
    "    spots_data = data.get('spots_data', [])\n",
    "    if spots_data:\n",
    "        df_spots = pd.DataFrame(spots_data)\n",
    "        \n",
    "        print(\"üîç Current DataFrame Info:\")\n",
    "        print(f\"Shape: {df_spots.shape}\")\n",
    "        print(f\"Memory usage: {df_spots.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        print(\"\\nüìã Current Data Types:\")\n",
    "        print(df_spots.dtypes)\n",
    "        \n",
    "        # Show memory usage by column\n",
    "        print(\"\\nüíæ Memory Usage by Column:\")\n",
    "        memory_usage = df_spots.memory_usage(deep=True)\n",
    "        for col, usage in memory_usage.items():\n",
    "            if usage > 0:\n",
    "                print(f\"  {col}: {usage / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41677cf6",
   "metadata": {},
   "source": [
    "### Memory Optimization\n",
    "\n",
    "Let's optimize the data types to reduce memory usage. We can convert float64 to float32 and use smaller integer types where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dataframe_dtypes(df):\n",
    "    \"\"\"Optimize DataFrame data types for memory efficiency.\"\"\"\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_optimized = df.copy()\n",
    "    \n",
    "    # Define type mappings for specific columns\n",
    "    dtype_map = {\n",
    "        # Boolean columns\n",
    "        'valid_spot': 'bool',\n",
    "        'reassigned': 'bool', \n",
    "        'unmixed_removed': 'bool',\n",
    "        \n",
    "        # String columns (will convert to category if beneficial)\n",
    "        'chan': 'category',\n",
    "        'unmixed_chan': 'category',\n",
    "        'cell_id': 'category',\n",
    "        \n",
    "        # Integer columns - use smaller types where possible\n",
    "        'round': 'int8',  # rounds are typically 1-10\n",
    "    }\n",
    "    \n",
    "    # Apply explicit type conversions\n",
    "    for col, dtype in dtype_map.items():\n",
    "        if col in df_optimized.columns:\n",
    "            try:\n",
    "                if dtype == 'category':\n",
    "                    df_optimized[col] = df_optimized[col].astype('category')\n",
    "                else:\n",
    "                    df_optimized[col] = df_optimized[col].astype(dtype)\n",
    "                print(f\"‚úÖ Converted {col} to {dtype}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not convert {col} to {dtype}: {e}\")\n",
    "    \n",
    "    # Convert float64 to float32 for numeric columns\n",
    "    float_cols = df_optimized.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        # Check if values fit in float32 range\n",
    "        max_val = df_optimized[col].max()\n",
    "        min_val = df_optimized[col].min()\n",
    "        \n",
    "        if pd.isna(max_val) or pd.isna(min_val):\n",
    "            continue\n",
    "            \n",
    "        # Float32 range is approximately ¬±3.4e38\n",
    "        if abs(max_val) < 3.4e38 and abs(min_val) < 3.4e38:\n",
    "            df_optimized[col] = df_optimized[col].astype('float32')\n",
    "            print(f\"‚úÖ Converted {col} from float64 to float32\")\n",
    "    \n",
    "    # Convert large integers to smaller types if possible\n",
    "    int_cols = df_optimized.select_dtypes(include=['int64']).columns\n",
    "    for col in int_cols:\n",
    "        if col in dtype_map:\n",
    "            continue  # Already handled above\n",
    "            \n",
    "        max_val = df_optimized[col].max()\n",
    "        min_val = df_optimized[col].min()\n",
    "        \n",
    "        # Try int32 first, then int16, then int8\n",
    "        if min_val >= -2147483648 and max_val <= 2147483647:\n",
    "            df_optimized[col] = df_optimized[col].astype('int32')\n",
    "            print(f\"‚úÖ Converted {col} from int64 to int32\")\n",
    "        elif min_val >= -32768 and max_val <= 32767:\n",
    "            df_optimized[col] = df_optimized[col].astype('int16')\n",
    "            print(f\"‚úÖ Converted {col} from int64 to int16\")\n",
    "        elif min_val >= -128 and max_val <= 127:\n",
    "            df_optimized[col] = df_optimized[col].astype('int8')\n",
    "            print(f\"‚úÖ Converted {col} from int64 to int8\")\n",
    "    \n",
    "    return df_optimized\n",
    "\n",
    "# Apply optimization if we have data\n",
    "if data is not None and 'spots_data' in data:\n",
    "    print(\"üöÄ Optimizing DataFrame...\")\n",
    "    df_spots_optimized = optimize_dataframe_dtypes(df_spots)\n",
    "    \n",
    "    # Compare memory usage\n",
    "    original_memory = df_spots.memory_usage(deep=True).sum() / 1024**2\n",
    "    optimized_memory = df_spots_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "    savings = original_memory - optimized_memory\n",
    "    percentage_saved = (savings / original_memory) * 100\n",
    "    \n",
    "    print(f\"\\nüìä Memory Usage Comparison:\")\n",
    "    print(f\"Original:  {original_memory:.2f} MB\")\n",
    "    print(f\"Optimized: {optimized_memory:.2f} MB\")\n",
    "    print(f\"Savings:   {savings:.2f} MB ({percentage_saved:.1f}% reduction)\")\n",
    "    \n",
    "    # Show optimized dtypes\n",
    "    print(f\"\\nüéØ Optimized Data Types:\")\n",
    "    print(df_spots_optimized.dtypes)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7745d9",
   "metadata": {},
   "source": [
    "### Memory Usage Analysis\n",
    "\n",
    "Let's analyze the memory impact and see specific column optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78298cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data is not None and 'spots_data' in data:\n",
    "    # Create a detailed comparison\n",
    "    print(\"üìà Detailed Memory Comparison by Column:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    original_usage = df_spots.memory_usage(deep=True)\n",
    "    optimized_usage = df_spots_optimized.memory_usage(deep=True)\n",
    "    \n",
    "    print(f\"{'Column':<20} {'Original':<12} {'Optimized':<12} {'Savings':<10} {'%':<6}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_original = 0\n",
    "    total_optimized = 0\n",
    "    \n",
    "    for col in df_spots.columns:\n",
    "        orig_mem = original_usage[col] / 1024  # KB\n",
    "        opt_mem = optimized_usage[col] / 1024   # KB\n",
    "        savings = orig_mem - opt_mem\n",
    "        pct_savings = (savings / orig_mem * 100) if orig_mem > 0 else 0\n",
    "        \n",
    "        total_original += orig_mem\n",
    "        total_optimized += opt_mem\n",
    "        \n",
    "        print(f\"{col:<20} {orig_mem:>8.1f} KB {opt_mem:>8.1f} KB {savings:>6.1f} KB {pct_savings:>4.1f}%\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    total_savings = total_original - total_optimized\n",
    "    total_pct = (total_savings / total_original * 100) if total_original > 0 else 0\n",
    "    print(f\"{'TOTAL':<20} {total_original:>8.1f} KB {total_optimized:>8.1f} KB {total_savings:>6.1f} KB {total_pct:>4.1f}%\")\n",
    "    \n",
    "    # Show biggest memory savers\n",
    "    print(f\"\\nüèÜ Biggest Memory Savers:\")\n",
    "    savings_by_col = {}\n",
    "    for col in df_spots.columns:\n",
    "        orig_mem = original_usage[col]\n",
    "        opt_mem = optimized_usage[col]\n",
    "        savings_by_col[col] = orig_mem - opt_mem\n",
    "    \n",
    "    top_savers = sorted(savings_by_col.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for col, savings in top_savers:\n",
    "        if savings > 0:\n",
    "            print(f\"  {col}: {savings/1024:.1f} KB saved\")\n",
    "    \n",
    "    # Update our working dataframe to the optimized version\n",
    "    df_spots = df_spots_optimized\n",
    "    print(f\"\\n‚úÖ DataFrame updated to optimized version!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for detailed analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5eb0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Available channel pairs: [['488', '514'], ['488', '561'], ['488', '594'], ['488', '638'], ['514', '561'], ['514', '594'], ['514', '638'], ['561', '594'], ['561', '638'], ['594', '638']]\n",
      "\n",
      "üìã Spots DataFrame shape: (5000, 12)\n",
      "Columns: ['spot_id', 'chan', 'r', 'dist', 'unmixed_chan', 'reassigned', 'unmixed_removed', 'chan_488_intensity', 'chan_514_intensity', 'chan_561_intensity', 'chan_594_intensity', 'chan_638_intensity']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_id</th>\n",
       "      <th>chan</th>\n",
       "      <th>r</th>\n",
       "      <th>dist</th>\n",
       "      <th>unmixed_chan</th>\n",
       "      <th>reassigned</th>\n",
       "      <th>unmixed_removed</th>\n",
       "      <th>chan_488_intensity</th>\n",
       "      <th>chan_514_intensity</th>\n",
       "      <th>chan_561_intensity</th>\n",
       "      <th>chan_594_intensity</th>\n",
       "      <th>chan_638_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7966486</td>\n",
       "      <td>638</td>\n",
       "      <td>0.659797</td>\n",
       "      <td>0.554720</td>\n",
       "      <td>638</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24.28455</td>\n",
       "      <td>4.731705</td>\n",
       "      <td>15.53658</td>\n",
       "      <td>7.674800</td>\n",
       "      <td>495.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5243252</td>\n",
       "      <td>561</td>\n",
       "      <td>0.804026</td>\n",
       "      <td>0.573335</td>\n",
       "      <td>561</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12.07317</td>\n",
       "      <td>7.170730</td>\n",
       "      <td>342.01690</td>\n",
       "      <td>39.495940</td>\n",
       "      <td>19.414635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7691947</td>\n",
       "      <td>638</td>\n",
       "      <td>0.540704</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>638</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.25203</td>\n",
       "      <td>5.178860</td>\n",
       "      <td>49.23578</td>\n",
       "      <td>14.373985</td>\n",
       "      <td>415.823100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4108598</td>\n",
       "      <td>514</td>\n",
       "      <td>0.907056</td>\n",
       "      <td>0.289419</td>\n",
       "      <td>488</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>215.69172</td>\n",
       "      <td>241.910580</td>\n",
       "      <td>14.23578</td>\n",
       "      <td>51.886180</td>\n",
       "      <td>12.869920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4060257</td>\n",
       "      <td>514</td>\n",
       "      <td>0.874865</td>\n",
       "      <td>0.155913</td>\n",
       "      <td>488</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>207.57724</td>\n",
       "      <td>195.634160</td>\n",
       "      <td>13.26016</td>\n",
       "      <td>48.471540</td>\n",
       "      <td>15.861786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spot_id chan         r      dist unmixed_chan  reassigned  unmixed_removed  \\\n",
       "0  7966486  638  0.659797  0.554720          638       False            False   \n",
       "1  5243252  561  0.804026  0.573335          561       False            False   \n",
       "2  7691947  638  0.540704  0.676400          638       False            False   \n",
       "3  4108598  514  0.907056  0.289419          488        True            False   \n",
       "4  4060257  514  0.874865  0.155913          488        True            False   \n",
       "\n",
       "   chan_488_intensity  chan_514_intensity  chan_561_intensity  \\\n",
       "0            24.28455            4.731705            15.53658   \n",
       "1            12.07317            7.170730           342.01690   \n",
       "2             8.25203            5.178860            49.23578   \n",
       "3           215.69172          241.910580            14.23578   \n",
       "4           207.57724          195.634160            13.26016   \n",
       "\n",
       "   chan_594_intensity  chan_638_intensity  \n",
       "0            7.674800          495.674800  \n",
       "1           39.495940           19.414635  \n",
       "2           14.373985          415.823100  \n",
       "3           51.886180           12.869920  \n",
       "4           48.471540           15.861786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Spot details available for 5000 spots\n",
      "Example spot 7966486: {'cell_id': 41951, 'round': '4', 'z': 1150, 'y': 5895, 'x': 2717}\n",
      "\n",
      "üíæ Fused S3 paths (5 files):\n",
      "  s3://aind-open-data/HCR_749315_2025-05-08_14-00-00_processed_2025-05-17_22-15-31/image_tile_fusing/fused/channel_488.zarr\n",
      "  s3://aind-open-data/HCR_749315_2025-05-08_14-00-00_processed_2025-05-17_22-15-31/image_tile_fusing/fused/channel_514.zarr\n",
      "  s3://aind-open-data/HCR_749315_2025-05-08_14-00-00_processed_2025-05-17_22-15-31/image_tile_fusing/fused/channel_561.zarr\n",
      "  ... and 2 more\n",
      "\n",
      "üßÆ Ratios matrix shape: (5, 5)\n",
      "\n",
      "üìà Summary stats: 5 records\n"
     ]
    }
   ],
   "source": [
    "if data is not None:\n",
    "    # Extract channel pairs\n",
    "    channel_pairs = data.get('channel_pairs', [])\n",
    "    print(f\"üìä Available channel pairs: {channel_pairs}\")\n",
    "    \n",
    "    # Convert spots data to DataFrame\n",
    "    spots_data = data.get('spots_data', [])\n",
    "    if spots_data:\n",
    "        df_spots = pd.DataFrame(spots_data)\n",
    "        print(f\"\\nüìã Spots DataFrame shape: {df_spots.shape}\")\n",
    "        print(f\"Columns: {list(df_spots.columns)}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(df_spots.head())\n",
    "    \n",
    "    # Extract spot details\n",
    "    spot_details = data.get('spot_details', {})\n",
    "    print(f\"\\nüéØ Spot details available for {len(spot_details)} spots\")\n",
    "    if spot_details:\n",
    "        # Show example spot detail\n",
    "        sample_spot_id = list(spot_details.keys())[0]\n",
    "        print(f\"Example spot {sample_spot_id}: {spot_details[sample_spot_id]}\")\n",
    "    \n",
    "    # Extract S3 paths\n",
    "    fused_s3_paths = data.get('fused_s3_paths', [])\n",
    "    print(f\"\\nüíæ Fused S3 paths ({len(fused_s3_paths)} files):\")\n",
    "    for path in fused_s3_paths[:3]:  # Show first 3\n",
    "        print(f\"  {path}\")\n",
    "    if len(fused_s3_paths) > 3:\n",
    "        print(f\"  ... and {len(fused_s3_paths) - 3} more\")\n",
    "    \n",
    "    # Check for optional data\n",
    "    if 'ratios' in data:\n",
    "        ratios = np.array(data['ratios'])\n",
    "        print(f\"\\nüßÆ Ratios matrix shape: {ratios.shape}\")\n",
    "    \n",
    "    if 'summary_stats' in data:\n",
    "        summary_stats = data['summary_stats']\n",
    "        print(f\"\\nüìà Summary stats: {len(summary_stats)} records\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to extract!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32c2da",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data\n",
    "\n",
    "Create basic visualizations to explore the spot data and understand the channel relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data is not None and 'spots_data' in data:\n",
    "    # Create scatter plot for first channel pair\n",
    "    if len(channel_pairs) > 0 and len(df_spots) > 0:\n",
    "        # Get first channel pair\n",
    "        x_chan, y_chan = channel_pairs[0]\n",
    "        x_col = f'chan_{x_chan}_intensity'\n",
    "        y_col = f'chan_{y_chan}_intensity'\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        fig.suptitle(f'SeeSpot Data Analysis: {x_chan} vs {y_chan} Channels', fontsize=16)\n",
    "        \n",
    "        # 1. Scatter plot of channel intensities\n",
    "        colors = ['red' if x else 'blue' for x in df_spots.get('reassigned', [False] * len(df_spots))]\n",
    "        axes[0,0].scatter(df_spots[x_col], df_spots[y_col], c=colors, alpha=0.6, s=20)\n",
    "        axes[0,0].set_xlabel(f'{x_chan} Intensity')\n",
    "        axes[0,0].set_ylabel(f'{y_chan} Intensity')\n",
    "        axes[0,0].set_title('Channel Intensities (Red=Reassigned, Blue=Original)')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Histogram of R values\n",
    "        axes[0,1].hist(df_spots['r'], bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "        axes[0,1].set_xlabel('R Value')\n",
    "        axes[0,1].set_ylabel('Frequency')\n",
    "        axes[0,1].set_title('Distribution of R Values')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Histogram of distance values\n",
    "        axes[1,0].hist(df_spots['dist'], bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "        axes[1,0].set_xlabel('Distance')\n",
    "        axes[1,0].set_ylabel('Frequency')\n",
    "        axes[1,0].set_title('Distribution of Distance Values')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Channel distribution\n",
    "        chan_counts = df_spots['chan'].value_counts()\n",
    "        axes[1,1].bar(chan_counts.index, chan_counts.values, alpha=0.7, color='purple')\n",
    "        axes[1,1].set_xlabel('Channel')\n",
    "        axes[1,1].set_ylabel('Count')\n",
    "        axes[1,1].set_title('Original Channel Distribution')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"üìä Summary Statistics:\")\n",
    "        print(f\"Total spots: {len(df_spots)}\")\n",
    "        print(f\"Reassigned spots: {df_spots.get('reassigned', []).sum() if 'reassigned' in df_spots.columns else 'N/A'}\")\n",
    "        print(f\"Average {x_chan} intensity: {df_spots[x_col].mean():.2f}\")\n",
    "        print(f\"Average {y_chan} intensity: {df_spots[y_col].mean():.2f}\")\n",
    "        print(f\"Average R value: {df_spots['r'].mean():.3f}\")\n",
    "        print(f\"Average distance: {df_spots['dist'].mean():.3f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for visualization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca265e",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You now have a working example of how to query the SeeSpot API! Here are some suggestions for further exploration:\n",
    "\n",
    "### Additional API Endpoints\n",
    "- **`/api/datasets`**: List available datasets\n",
    "- **`/api/datasets/set-active`**: Switch to a different dataset  \n",
    "- **`/api/create-neuroglancer-link`**: Generate neuroglancer visualization links\n",
    "\n",
    "### Data Analysis Ideas\n",
    "- **Channel comparison**: Analyze intensity relationships across all channel pairs\n",
    "- **Reassignment patterns**: Study which spots get reassigned and why\n",
    "- **Spatial analysis**: Use spot coordinates for spatial clustering\n",
    "- **Quality metrics**: Explore the relationship between R values and data quality\n",
    "\n",
    "### Performance Tips\n",
    "- Use `sample_size` parameter to control response size\n",
    "- Set `force_refresh=False` to leverage server-side caching\n",
    "- Consider pagination for very large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
